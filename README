

= Snapper

This is a tool to quickly go through one or more snaps.  It currently
can not work with perfpmr output but that is planned.

== Usage

The simplest form is:

  snapper.rb path/to/snap

where +path/to/snap+ is to the top directory of the snap -- the
directory that contains general and other directories.  A list of
snaps can be supplied on a single command line and ultimately that is
where this tool is heading so that configuration errors in VIOS HA
environments can be found or following the packets from a particular
interface on a particular virtual client out through the SEA to its
real adapter and out to the real network.

  Usage: snapper.rb [options] <path to snap1> [ <path to snap2> ... ]
      -D, --dump                       For each snap, creates a .ruby.dump.gz file
				       at the base directory of the snap with the
				       parse tree of the snap.  This file will be
				       automatically loaded instead of re-parsing
				       the files within the snap.
      -k, --print_keys                 Print the top level keys
      -l, --level N                    Output verbosity level from -1 to 11
				       default is 1
      -h, -?, --help                   Show this message

The +-D+ option is detailed in the -D[#label-D] section.

The +--print_keys+ option is to help with debugging new code.  It
prints out the keys in the top level database container.

The levels are described in the Levels[#label-Levels] section.

== Features

Here are the list of features for snapper

=== Configurable

Snapper is written in Ruby and since Ruby is interpreted, it allows
snapper to be highly configurable.  Some concepts I have are not
implemented yet but I know how I will implement them.  In the end,
almost all of snapper will be configurable by the individual user.  As
will be described, snapper operates in phases.  The methods used in
all of these phases allow users to add in their own code.  In brief, a
user will be able to have a .snapper directory in his home directory
with Ruby snippets that will be loaded when snapper is run.

"Oh Gee..", you say, "I don't know Ruby".  True enough but you
probably can mimic other code snippets and poke at them until you get
them to do what you want.  Since Ruby is interpreted, the source is
visible and so you will not need to really "create" fresh Ruby code as
much as bastardize existing parts... very similar to how typical
developers work <smirk>.

Currently, snapper is glaringly focused on TCP Kernel users but I
truly hope some volunteers step up and help make this more useful to
other groups.

=== Phases

Snapper is set up to work in four phases.  

The first phase is the parse phase where the snap is ransacked and as
much of it is understood as possible.  Details of parsing will be
described in the Parsers[#label-Parsers] section.  If the +-D+ option
was given, a compressed version of the parse tree is saved in
+.ruby.snap.bz+ in the top level directory.  See -D[#label-D] for more
details.  Adding a parser depends upon if an entire file needs to be
parsed (see Snapper.add_file_parsing_patterns) or if a section of a
"dot file" needs to be parsed (see DotFileParser and
DotFileParser#parse).

The second phase is after the parsing of each snap and are general
routines that go through the parsed data making things easier to work
with for the later stages.  The best example of this is Devices which
goes through the parsed data creating a Device for each logical device
in the CuAt output.  The Device will have a name like 'ent0' as well
as entries for the cudv, cuat, pddv, pdat, entstat, lsattr, errpt,
etc.  Devices knows where all those different pieces reside in the
snap and pulls them into one general object.  Another example is
Interfaces that pulls parsed data gathered from netstat -in as well as
ifconfig -a (if it is present) into a single object.  This allows
later processing to be more easily written.  See
Snapper.add_snap_processor for more details.

The third phase has not been implemented yet but will be called batch
processors to process the entire _batch_ of snaps.  These will be
called after all of the snaps have been parsed. This phase can detect
things like making sure that the control channel of two SEAs on two
different LPARs but on the same CEC are using the same VLAN tag.  The
first of these processors will group the snaps by CEC.

The fourth phrase is the output phase.  The output phrase is done via
Filter instances.  Currently all of the Filter instances are in the
Filters.rb file but eventually they will also be pulled in from user
config files.  You can view this file on the Filters page.

As mentioned, a user can add in a parser for a file that is currently
unparsed, he can add in a processing item that is kicked off in phase
2, and he can add in filters to more precisely control what he wants
to see in the output.

=== Levels

Levels go from -1 up to (as Spinal Tap says) 11.  Level of -1 is for
debugging.  All normal output is stopped and the user will only see
the debug statements.

The purpose of level 0 is to give a very quick overview of the set up.
The output from the sample snap is this:

  1 Host: aph001
  2 en9 IPv4:10.201.10.31 mtu:1500 mac:0.0.c9.d9.e8.bf ipkts:0 ierrs:0 opkts:14 oerrs:0
  3   ent9 pci/elxentdd
  4 en22 IPv4:10.201.55.100 mtu:1500 mac:e4.1f.13.fd.29.75 ipkts:190896 ierrs:0 opkts:210601 oerrs:0
  5   ent22 seadd
  6     ent2 pci/goentdd
  7     ent15 vioentdd
  8     ent10 vioentdd
  9 lo0 IPv4:127.0.0.1 IPv6: mtu:16896 mac: ipkts:5735 ierrs:0 opkts:5735 oerrs:0
 10 ent23 seadd
 11   ent20 ethchandd
 12     ent0 pci/elxentdd
 13     ent8 pci/elxentdd
 14   ent16 vioentdd
 15   ent11 vioentdd
 16 ent24 seadd
 17   ent21 ethchandd
 18     ent6 pci/elxentdd
 19     ent7 pci/elxentdd
 20   ent17 vioentdd
 21   ent12 vioentdd
 22 ent25 seadd
 23   ent3 pci/goentdd
 24   ent18 vioentdd
 25   ent13 vioentdd
 26 ent26 seadd
 27   ent4 pci/goentdd
 28   ent19 vioentdd
 29   ent14 vioentdd

Line 1 is the host name.  I do not group CECs yet but that will be
done so the simple output will start with the CEC id, then the
hostname.

Line 2 starts what basically comes from netstat -in.  It is the
interfaces crunched down to one line with all really useful info on
one line.  Each interface, also prints the device associated with it
nested one level deeper.

Line 3 is the device that line 2 is on top of.  For level 0, only the
device name and the driver are printed.  I could add the description
as seen from lsdev.adapters but I personally find that useless.

Line 4 starts the 2nd interface.  In this case, the device on line 5
is a SEA so it is printed along with the adapters that it contains
nested one level further.  A bugabo that needs to be addressed is the
entry on line 8 is the control adapter.  It needs to be marked as
such otherwise users might mistake it as one of the bridging VEAs.
Also, the PVID adapter probably should be marked as well.

Line 9 ends the interface section with loopback.

Lines 10 through 29 are now the list of SEAs.  Only the SEAs that have
not already been printed are listed (e.g. ent22 is not repeated).

Currently I am thinking that level 0 output is done.  I can't think of
what else I want to add to it.  Remember, the default is level 1 so the
user must ask for level 0 output so I assume he really does want minimal
output.

The default output of snapper allowing the level to default to 1 is
shown below:

  1 Host: aph001
  2 en9 IPv4:10.201.10.31 mtu:1500 mac:0.0.c9.d9.e8.bf ipkts:0 ierrs:0 opkts:14 oerrs:0
  3   ent9 pci/elxentdd
  4     Receive Statistics,Receive Errors:685617
  5     Receive Statistics,DMA Overrun:685617
  6 
  7 en22 IPv4:10.201.55.100 mtu:1500 mac:e4.1f.13.fd.29.75 ipkts:190896 ierrs:0 opkts:210601 oerrs:0
  8   ent22 seadd
  9     16 error log entries
 10     ent2 pci/goentdd
 11     ent15 vioentdd
 12       Port VLAN ID: 300
 13       Hypervisor Send Failures: 4927
 14     ent10 vioentdd
 15       Port VLAN ID: 1300
 16 
 17 lo0 IPv4:127.0.0.1 IPv6: mtu:16896 mac: ipkts:5735 ierrs:0 opkts:5735 oerrs:0
 18
 19 ent23 seadd
 20   19 error log entries
 21   Receive Statistics,Receive Errors:842400
 22   Receive Statistics,DMA Overrun:842400
 23   Other Statistics,ICMP error packets sent:931
 24   ent20 ethchandd
 25     Receive Statistics,Receive Errors:842400
 26     Receive Statistics,DMA Overrun:842400
 27     ent0 pci/elxentdd
 28       Receive Statistics,Receive Errors:156783
 29       Receive Statistics,DMA Overrun:156783
 30     ent8 pci/elxentdd
 31       Receive Statistics,Receive Errors:685617
 32       Receive Statistics,DMA Overrun:685617
 33   ent16 vioentdd
 34     Port VLAN ID: 4094 VLAN Tag IDs [104, 105, 106, 201, 202, 203, 205, 209, 210, 248, 250, 267, 288, 801, 802]
 35     Hypervisor Send Failures: 21562715
 36   ent11 vioentdd
 37     Port VLAN ID: 1310
 38 
 39 ent24 seadd
 40   14 error log entries
 41   ent21 ethchandd
 42     ent6 pci/elxentdd
 43     ent7 pci/elxentdd
 44   ent17 vioentdd
 45     Port VLAN ID: 320
 46     Hypervisor Send Failures: 141
 47   ent12 vioentdd
 48     Port VLAN ID: 1320
 49 
 50 ent25 seadd
 51   12 error log entries
 52   ent3 pci/goentdd
 53   ent18 vioentdd
 54     Port VLAN ID: 4093 VLAN Tag IDs [270, 275]
 55     Hypervisor Send Failures: 1250
 56   ent13 vioentdd
 57     Port VLAN ID: 1340
 58 
 59 ent26 seadd
 60   16 error log entries
 61   ent4 pci/goentdd
 62   ent19 vioentdd
 63     Port VLAN ID: 4092 VLAN Tag IDs [271, 272, 1288]
 64     Hypervisor Send Failures: 6942
 65   ent14 vioentdd
 66     Port VLAN ID: 1350

The flow is the same.  The CEC name (to be done), host name,
interfaces, and then the SEAs.  In level 1 mode, the intent is to
still be very concise yet point to possible problem areas.  level 1
output will contain alerts which is yet to be done as well.  The
alerts will be per snap so they will come out after the CEC's name but
before the host name.

As you can see on samples of line 4 and 5, entstat fields with the
word "error", "overrun" or "underrun" are printed out *if* the value
of the field is not zero.

Line 9 shows a sample of level 1 output for error log entries.  A
count of the error log entries is done to clue the user into the fact
that this device is having errors in the error log.

Line 34 shows a sample of the VLAN tag information for the VEAs.
Since that is very often needed I put that out in the level 1 output
as well.

Line 35 is our trusty Hypervisor errors we all love.

Since level 1 is the default, the intent is to make the output concise
yet point the user to the trouble areas.  Higher levels can be used if
the user needs more details.  For example, at level 4, all of the
attributes are printed out under the device.  At level 2 through 5,
duplicate error log entries are removed.  As time go by, the objective
is to come up with a "philosophy" of each level and then create
Filters (to be explained) that fit that objective.

The purpose of level 11 is to essentially "dump" everything.  The
containers like Ethchan and Sea have filters for level 11 since they
need to dump out the adapters beneath them.  But most other things do
not.  Instead they revert to a Filter for Item that dumps the list of
flatten keys.

=== Filters

Currently there are some concepts that I may change or alter but here
is the current set up.

The lower level "object" that the parsers create is called an Item.
Subclasses of Item are Device, Interface, etc.  There is a tree of
classes for entstat starting with the base of Entstat which is a
subclass of Item and then specific parsers for the adapters are
subclassed off of Entstat such as Entstat_goent or Entstat_ethchan.

A filter is added like this:

 Filter.add("Device", { level: 0 .. 11 }) do |context, item|
   unless item.printed
     context.output("#{item.cudv.name} #{item.cudv.ddins}")
     item['errpt'].print_list(context.nest) if item['errpt']
     item['entstat'].print(context.nest)    if item['entstat']
     item['lsattr'].print(context.nest)     if item['lsattr']
   end
 end

It is added to the Class that is the first argument.  The second
argument is the levels that it is valid for.  The 0 .. 11 is exactly
what it appears -- a range from 0 to 11 inclusive.  We can see that
this calls context.output with a string which ends up going to
standard output.  We also see it calling print_list for items within
the device such as the list of error log entries, the entstat output,
and the lsattr output.  As mentioned, this hangs off of the Device
class.

If, for example, a Sea needs to be printed, since Sea is a subclass of
Device, and Device is a subclass of Item, the list of available
filters come from (in order) Sea, Device, and then Item.  Currently
the list is searched until the *first* filter matches the level
specified on the command line.  If the command line specified an
output level of 4 and Sea does not have a filter for level 4, then the
above Device entry will be used and the Filter entries for Item will
never be really considered.

This current scheme has issues with code reuse and I may alter it.

As the parsers parse the files, they create trees of items.  For
example, in the typical intro for an entstat output we see:

 Transmit Statistics:                          Receive Statistics:
 --------------------                          -------------------
 Packets: 241295                               Packets: 238619
 Bytes: 1995516069                             Bytes: 18097146
 Interrupts: 0                                 Interrupts: 155955
 Transmit Errors: 0                            Receive Errors: 0
 Packets Dropped: 0                            Packets Dropped: 0
                                               Bad Packets: 0

Off of the top Entstat Item will be an entry for 'Transmit Statistics'
as well as an entry for 'Receive Statistics'.  If you have used hashes
in other languages (like Perl), then you should be familiar with a
syntax like:

item['Receive Statistics']

which returns a hash with entries for each of the things listed below
receive statistics such as Packets, Bytes, Interrupts, etc.

Items have many cute features.  One of them is the key is actually
modified so you can also retrieve the same information via

item['receive_statistics']

and you can also retrieve it using dot notition

item.receive_statistics

These can be cascaded so

item.receive_statistics.packets

would return 238619 and the 238619 is already recognized as an integer
so arithmatic can be done on it.  It should be not super difficult to
compute error rates or percentages.

But, all this parsing and nesting leaves filtering hard to do.  You
don't really want to pre-find all of the entstat output that have
"error" somewhere in them and then create special statements digging
into the structures just to ask if it is not zero, then print it out.

Added to Item is a method called flat_keys.  Rather than explain what
it does, I'll just show you how to use it:

 1 Filter.add("Entstat", { level: 1 }) do |context, item|
 2   item.flat_keys.each do |key, vavlue|
 3     if /error|overrun|underrun/i.match(key) && value != 0
 4       context.output("#{key}:#{value}")
 5     end
 6   end
 7 end

This is a filter added to Entstat so all of the Entstat subclasses
could use it.  The output of flat_keys is a list of tuples.  The first
is the flattened key, the second is the value.  The flattened key is
the list of hash keys needed to get to the entry separated by commas.
For example, the number of packets received has a flattened key of
"Receive Statistics,Packets" and in our example, value would be
238619.

Lines 2 and 6 create a loop.  Inside that loop, key and value are set
with successive values.  The if statement starting on line 3 asks if
the key matches the regular expression.  The i at the end is to make
the match ignore case.  If the regular expression matches the key and
the value is not zero, we send to the output a string with the key and
the value.  In the second sample output above where level is set to 1,
this is how lines 21 through 23 and many other lines of output got
produced.

One of the powerful features of Ruby is how code blocks are treated.
They are treated (surprise surprise) as objects.  When Filter.add is
called, it actually has three arguments.  The name, the level, and the
code block starting at the "do" on line 1 and ending at line 7.  When
the filter code determines that the filter matches and needs to
execute, it just calls the code block (called a Proc) passing the
arguments that it wants to pass.  In this case, the context and the
item.

We have not talked about context.  For now, its enough to know that it
has two methods.  context.level is the level specified by the user on
the command line.  And context.output will get the argument to
standard output.

=== Parsers

The top parser is called based upon the file name.  Currently, this
list can not be modified but we can figure out some way to change that
I'm sure.

For a snap, many files use the DotFileParser.  The files have a
structure to them.  For example a section from tcpip.snap is shown
below.


 .....
 .....    netstat -in
 .....
 
 Name  Mtu   Network     Address           Ipkts Ierrs    Opkts Oerrs  Coll
 en10  1500  link#2      e4.1d.2d.e.fd.60 3367529084     0 3619873322    28     0
 en10  1500  10.126.137. 10.126.137.189   3367529084     0 3619873322    28     0
 en11  9000  link#3      e4.1d.2d.e.fe.1  223991557     0 144231257     5     0
 en11  9000  10.125.32   10.125.32.126    223991557     0 144231257     5     0
 lo0   16896 link#1                       21470805     0 21467696     0     0
 lo0   16896 127         127.0.0.1        21470805     0 21467696     0     0
 lo0   16896 ::1%1                        21470805     0 21467696     0     0
 
 .....
 .....    netstat -v
 .....
 
 -------------------------------------------------------------
 ETHERNET STATISTICS (ent10) :
 Device Type: IEEE 802.3ad Link Aggregation
 Hardware Address: e4:1d:2d:0e:fd:60
 Elapsed Time: 12 days 4 hours 46 minutes 32 seconds
 
 Between each set of output is a banner such as:
 
 .....
 .....    netstat -in
 .....

The DotFileParser converts the command "netstat -in" into a class by
removing all spaces, convert any non-alphanumeric characters into
underscores, and then capitalize the first character.  Thus, "netstat
-in" becomes Netstat_in  (the _ is from the -, not the space).

The DotFileParser then looks to see if a class with that name exists.
If it does, it creates an instance of calls parse on that instance.
If it does not, it uses a generic parser that doesn't really "parse"
but just saves the text.

The basic concept continues.  The Netstat_v parser pickes up the
string after Device Type, in our example "IEEE 802.3ad Link
Aggregation".  In this case, it is a two step process.  It looks to
see if any class has registered to parse that particular device.  In
this case, the Entstat_ethchan class has said that it can.  So an
instance of that class is created and parse is called.

When the instance is created, the file io object is passed to it as
well as the "database" created for this particular snap.  The parser
then parses the text from its io object and adds entries to the
database object.  Its probably eaiser for you just to review the code
than to read English text trying to describe it.

The net is however that if some piece of the snap currentl does not
have a parser for it, one can be created and added by the user.

=== PDA

The PDA in snapper is probably the piece that is most cutting edge.
In Automata theory, the simplest machine is the DFA -- deterministic
finite automata.  It is the same as a "state machine".  Given input,
it moves from state to state but the number of states is finite.
Regular expressions fall into the class of languages that DFAs can
parse.

The next step up is the push down automata which basically is a state
machine (DFA) with a stack added on that it can push states on to.
Since the stack is infinite (in theory), this machine can now move
between an infinite number of states.

To parse the entstat output, the PDA class was created.  Using
automata theory terms, "productions" are created that move the machine
from state to state as well as push and pop items from the stack.
With this machine, it is possible to nest down and understand, for
example, when an adapter has multiple transmit queues.  Each transmit
queue becomes its own object with its own set of attributes and
values.

A sample production is:

 # Sample Match:   |	Actor State: 
 # States Matched: :normal
 # New State:      :LACP_State
 # State Pushed:   yes
 # States Popped:  0
 # Matched the Actor State: and Partner State: lines
 PDA::Production.new("^\\s*(?<field>(Actor|Partner) State):\\s*$", [:normal, :consumeAll], :LACP_State) do |md, pda|
   field = md[:field]
   value = WriteOnceHash.new
   pda.target[field] = value
   pda.push(value)
 end

The first argument is a regular expression that matches a line in the
entstat output.  Ruby (like other new languages) has magic regular
expressions so that the matches can easily be accessed after a match
is made.

This production says that it is valid if the machine is in the normal
or the consumeAll states.  It says that it moves to a new state -- the
LACP_State.

Within the code block, the first line retrieves the actual text of the
match.  The second line creates a new hash.  The WriteOnceHash is used
so that if the parser gets confused and tried to overwrite a previous
field, it throws an exception.  This makes parser errors obvious and
reduces the possibility that information is being lost in the parsing
phases.

A new field is added to the current target using the matched text as
the key and the new hash as its value.  A push is then done to push
the current state and target.  The new state, briefly is the same as
it was but the new target is the new hash +value+.  When the block
exits, because of the new state of +LACP_State, specified in the third
argument, that state will be entered.

Other Production rules become enabled now that we are in the
+LACP_State+.  In particular, a Production will pop the stack when the
empty line after the "Expired:" line is encountered returning us to
the previous state.

=== Alerts

At the end of parsing each snap, a Snap is created that includes the
database, the path to the top level snap directory, and a list of
alerts.  Likewise at the end of processing all of the snaps, just
before the start of phase 3, a Batch is created that has the list of
snaps, the command line options, and a list of alerts.

The concept is that the snap processors may add to the alert list of
the Snap and the batch processors may add alerts to the alert list of
the Batch.  These lists currently exist but the Alert class and the
routines to print them out do not.

I believe the Alert class will have a text message and it may include
a coloring or it may be that Alerts are always colored red or it may
be that I refuse to do any text coloring at all or (most likely) will
default on but will have a command line option to turn it off and will
automatically turn off when the output is not a tty.

=== -D

When the +-D+ command line option is given, snapper will dump the
current state of the database out to a file called +.ruby.snap.gz+ in
the top level directory as the snap.  Once this file is created, it
will be used in place of the phase 1 parsing.  Note that the dump
currently occurs before the phase 2 processing.  Also, if you are
adding features to snapper, you might need to delete the file to get
the new features to work because the file is really a saved state.  If
you are adding or modifying a parser in particular, the reloaded saved
state will be from before the changes made to the parser.

=== html

Currently this is all broken.

== ToDos

1.  From the command line, set a global and a per class log level.

1.  From the command line, set an output file for the log
    information.  Again it would be nice if this could be done
    globally as well as per class.

1.  Create a Snap and a Batch class so their fields can be documented
    rather than just use OpenStruct.

1.  Create Alerts.

1.  Create batch processors.

1.  Fix the HTML output.

1.  Given a single directory with multiple snaps under it, process the
    individual snaps as if the paths to their base directories had
    been listed on the command line.
 
1.  Create a way for invoker of print to either include a text string
    that will proceed the first line of output or be appended to the
    first line of output.  It would also be nice if context.output
    could have options such as adding color or not putting a new
    line in every case.

1.  Add ability to direct output to a file from the command line
    rather than redirect stdout.

1.  Fix the parser for lsattr.  The batch of attributes need to be
    considered as a whole and the indent column for the value,
    description, and alterable field can be determined by scanning
    vertically for columns of spaces.  Not impossible.  Just not what
    I wanna do right now.
